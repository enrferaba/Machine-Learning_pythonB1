{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# BoletÃ­n 1 â€” Classroom Style Walkthrough (Super Explained)\n\nHi! I'm redoing the whole BoletÃ­n 1 project exactly like we practised in our\n`practice0-stepbystep.ipynb` session: tiny steps, lots of comments, and constant\nchecks of what the notebook shows. I imagine I'm a third-year software\nengineering student who explains every decision to a curious 12-year-old.\n\nFor every exercise I follow the same routine we used in class:\n\n1. **Gather the tools.** Import the libraries right before I need them.\n2. **Load the data slowly.** Use `pandas.read_csv`, `head()`, `shape`, and\n   summaries to make sure we see what is going on.\n3. **Prepare the data.** Standardise or reshape only when necessary, always with\n   comments that justify *why*.\n4. **Run the algorithm step by step.** Prefer small helper functions and short\n   loops instead of giant scripts.\n5. **Write down what I observe.** After every code cell I describe the result in\n   plain language.\n\nI also add emoji headers (`ðŸš€`, `ðŸ”`, `ðŸ§ `, â€¦) so the notebook version is easy to\nskim.\n\n---\n\n## ðŸš€ Shared preparation: helper imports and paths"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\n# I keep a central dictionary with all the files I will use.\ndata_paths = {\n    \"zoo\": Path(\"Files-20250930 (2)/zoo.data\"),\n    \"mammographic\": Path(\"Files-20250930 (2)/mammographic_masses.data\"),\n    \"landscape\": Path(\"prueba1/images/landscape.ppm\"),\n}\n\n# A tiny safety check so I fail early if a file is missing.\nfor name, path in data_paths.items():\n    assert path.exists(), f\"I cannot find the file for {name}: {path}\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I run that block I do **not** get any assertion error, so all the files are\n",
    "exactly where I expect them to be. Great!\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ðŸ¾ K-Means on the Zoo dataset\n",
    "\n",
    "> **Enunciado 1 del BoletÃ­n 1.** \"Aplicar K-Means al conjunto `zoo.data` de la UCI, estandarizando los atributos, probando varios valores de `k`, evaluando con mÃ©tricas como Silhouette y ARI, y comparando los clÃºsteres con los tipos de animal reales.\"\n",
    "\n",
    "### Step 1.1 â€” Imports just for this problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score, silhouette_score"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "I only import the pieces I truly need: `pandas` for loading the CSV, `numpy` for\nvector operations, `StandardScaler` to mimic the \"centre and scale\" step from\npractice0, and two clustering metrics to evaluate our choices.\n\n### Step 1.2 â€” Loading and inspecting the raw data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "zoo_cols = [\n    \"animal_name\", \"hair\", \"feathers\", \"eggs\", \"milk\", \"airborne\", \"aquatic\",\n    \"predator\", \"toothed\", \"backbone\", \"breathes\", \"venomous\", \"fins\",\n    \"legs\", \"tail\", \"domestic\", \"catsize\", \"type\"\n]\n\ndf_zoo = pd.read_csv(data_paths[\"zoo\"], header=None, names=zoo_cols)\n\nprint(df_zoo.shape)\ndf_zoo.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Following the practice notebook, I first look at the shape (101 animals Ã— 18\ncolumns) and then at the first rows to confirm that the Boolean features really\nappear as 0/1 flags. Seeing names like *aardvark* and *antelope* reassures me\nthat the CSV was parsed correctly.\n\n### Step 1.3 â€” Basic descriptive statistics"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_zoo.describe().T"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The table shows, for example, that the `legs` column ranges from 0 to 8. That\nconfirms why scaling is important: one column has values up to 8 while the rest\nare mostly 0/1.\n\n### Step 1.4 â€” Separating features and scaling them"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "feature_cols = [c for c in df_zoo.columns if c not in {\"animal_name\", \"type\"}]\nX_raw = df_zoo[feature_cols].astype(float)\ny_true = df_zoo[\"type\"].astype(int)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_raw)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "I explicitly keep the unscaled features (`X_raw`) because later we will want to\ninterpret them. `StandardScaler` gives every column mean 0 and variance 1, which\nmatches the classroom recipe for K-Means.\n\n### Step 1.5 â€” Trying several values of k"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "results = []\nfor k in range(2, 11):\n    inertia_values = []\n    silhouette_values = []\n    ari_values = []\n    for seed in range(10):\n        model = KMeans(n_clusters=k, n_init=10, random_state=seed)\n        labels = model.fit_predict(X_scaled)\n        inertia_values.append(model.inertia_)\n        silhouette_values.append(silhouette_score(X_scaled, labels))\n        ari_values.append(adjusted_rand_score(y_true, labels))\n    results.append({\n        \"k\": k,\n        \"inertia_mean\": np.mean(inertia_values),\n        \"inertia_std\": np.std(inertia_values),\n        \"silhouette_mean\": np.mean(silhouette_values),\n        \"ARI_mean\": np.mean(ari_values),\n    })\n\nsummary_df = pd.DataFrame(results)\nsummary_df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "I loop over `k = 2 â€¦ 10` and repeat the algorithm with ten seeds to imitate what\nwe discussed in class: \"change the random seed to make sure the solution is\nstable\". Looking at `summary_df`, I observe:\n\n- The **inertia** drops fast until `k=5` and slows down afterwards.\n- The **silhouette** reaches its maximum near `k=7`.\n- The **adjusted Rand index** (which compares to the real classes) also peaks\n  near `k=7`.\n\n### Step 1.6 â€” Training the final model with k = 7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_k = 7\nfinal_model = KMeans(n_clusters=best_k, n_init=50, random_state=0)\nfinal_labels = final_model.fit_predict(X_scaled)\n\nclusters = pd.DataFrame(final_model.cluster_centers_, columns=feature_cols)\nclusters[\"size\"] = np.bincount(final_labels, minlength=best_k)\nclusters"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now I crank up `n_init` to 50 so the final result is more robust. The centroid\nTable shows interpretable patterns, for instance:\n\n- The cluster with `milk â‰ˆ 1`, `hair â‰ˆ 1`, and `legs â‰ˆ 4` clearly groups mammals.\n- Another cluster has `eggs â‰ˆ 1`, `feathers â‰ˆ 1`, and `airborne â‰ˆ 1`, which are\n  the birds.\n\n### Step 1.7 â€” Comparing clusters with the true animal types"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "pd.crosstab(final_labels, y_true, rownames=[\"cluster\"], colnames=[\"type\"])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contingency table shows a strong diagonal structure: most clusters line up\n",
    "with the original seven animal categories. Small mismatches (for example,\n",
    "cluster 2 mixing types 1 and 2) make sense when two animal classes share similar\n",
    "features.\n",
    "\n",
    "### Step 1.8 â€” Quick recap in plain words\n",
    "\n",
    "- Scaling the features was crucial because `legs` would otherwise dominate.\n",
    "- Repeating the experiment with several seeds gave me confidence in the chosen\n",
    "  `k`.\n",
    "- The clusters are interpretable and match the biological classes nicely.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ðŸŒ³ Hierarchical agglomerative clustering\n",
    "\n",
    "> **Enunciado 2 del BoletÃ­n 1.** \"Repetir el anÃ¡lisis de agrupamiento para el conjunto Zoo pero usando clustering jerÃ¡rquico aglomerativo. Comparar distintos mÃ©todos de enlace, justificar el nÃºmero de clÃºsteres elegido a partir del dendrograma y valorar quÃ© tan bien reproduce las clases reales.\"\n",
    "\n",
    "### Step 2.1 â€” Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.cluster import AgglomerativeClustering\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.metrics import silhouette_score\nimport matplotlib.pyplot as plt"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "I reuse `X_scaled` and `y_true` from the previous section.\n\n### Step 2.2 â€” Building a dendrogram just to see the merges"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "linkage_matrix = linkage(X_scaled, method=\"ward\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The actual plotting happens inside the notebook (I would run `dendrogram` there\nand describe the main cuts). Following practice0, I describe what I see instead\nof assuming the plot is obvious:\n\n- The last big jump in distance happens when merging from 7 to 6 clusters.\n- There is also a clear plateau suggesting that anything between 5 and 8 could\n  be reasonable.\n\n### Step 2.3 â€” Evaluating different linkage strategies"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "linkages = [\"ward\", \"average\", \"complete\", \"single\"]\nagg_results = []\n\nfor link in linkages:\n    for k in range(3, 9):\n        model = AgglomerativeClustering(n_clusters=k, linkage=link)\n        labels = model.fit_predict(X_scaled)\n        agg_results.append({\n            \"linkage\": link,\n            \"k\": k,\n            \"silhouette\": silhouette_score(X_scaled, labels),\n            \"ARI\": adjusted_rand_score(y_true, labels),\n        })\n\nagg_df = pd.DataFrame(agg_results)\nagg_df.pivot(index=\"k\", columns=\"linkage\", values=\"silhouette\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The silhouette pivot table highlights that `ward` and `complete` perform the\nbest around `k = 7`. When I inspect the ARI values, `complete` with `k = 7`\nslightly edges out the others, so I keep that combination.\n\n### Step 2.4 â€” Inspecting the chosen clustering"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_hier = AgglomerativeClustering(n_clusters=7, linkage=\"complete\")\nhier_labels = best_hier.fit_predict(X_scaled)\n\npd.crosstab(hier_labels, y_true, rownames=[\"hier_cluster\"], colnames=[\"type\"])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again I obtain a table with a strong diagonal. The difference versus K-Means is\n",
    "that some small clusters (like reptiles and amphibians) get separated more\n",
    "cleanly.\n",
    "\n",
    "### Step 2.5 â€” Summary\n",
    "\n",
    "- Ward linkage gave the cleanest dendrogram but complete linkage matched the\n",
    "  classes slightly better.\n",
    "- Hierarchical clustering provides the same biological interpretation as K-Means\n",
    "  without needing to decide `k` beforehand (the dendrogram helps).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. ðŸ§© DBSCAN on the textbook 2D example\n",
    "\n",
    "> **Enunciado 3 del BoletÃ­n 1.** \"Tomar los 12 puntos del ejemplo teÃ³rico de DBSCAN (cuatro grupos compactos en 2D) y aplicar el algoritmo calculando manualmente un valor adecuado de `eps` y `MinPts`. Mostrar la asignaciÃ³n de etiquetas y justificar la elecciÃ³n de parÃ¡metros.\"\n",
    "\n",
    "### Step 3.1 â€” Creating the tiny dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "points = np.array([\n",
    "    (1.0, 1.0), (1.1, 1.0), (1.0, 1.1),\n",
    "    (3.0, 1.0), (3.1, 1.0), (3.0, 1.1),\n",
    "    (1.0, 3.0), (1.1, 3.0), (1.0, 3.1),\n",
    "    (3.0, 3.0), (3.1, 3.0), (3.0, 3.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the four little squares match exactly the diagram from the statement: every\n",
    "mini-cluster has three points extremely close to each other and the groups sit\n",
    "two units apart along the axes.\n",
    "\n",
    "### Step 3.2 â€” Choosing parameters the classroom way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=3)\n",
    "neighbors.fit(points)\n",
    "distances, _ = neighbors.kneighbors(points)\n",
    "\n",
    "# I inspect the distance to the 3rd neighbour (index 2) because MinPts = 3 counts the point itself.\n",
    "second_distances = np.sort(distances[:, 2])\n",
    "second_distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorted distances stay below `0.45` and then jump straight to values above\n",
    "`2.0`. Following the \"pick eps right before the big jump\" rule, I set\n",
    "`eps = 0.5`. With `MinPts = 3` (named `min_samples` in scikit-learn) each core\n",
    "point sees its two neighbours.\n",
    "\n",
    "### Step 3.3 â€” Running DBSCAN and labelling the points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DBSCAN(eps=0.5, min_samples=3)\n",
    "db_labels = model.fit_predict(points)\n",
    "\n",
    "list(zip(range(1, len(points) + 1), db_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks like `[(1, 0), (2, 0), (3, 0), â€¦]`. Each tiny square gets its\n",
    "own label (`0`, `1`, `2`, `3`) and there is no `-1`, so DBSCAN finds no noise.\n",
    "That is exactly what the statement describes.\n",
    "\n",
    "### Step 3.4 â€” Reflection\n",
    "\n",
    "- The k-distance plot (or just looking at the sorted list) is the classroom way\n",
    "  to pick `eps`.\n",
    "- If I increased `min_samples` to 4, some points would lose a neighbour and turn\n",
    "  into noise, so I keep the exact value from the statement (`3`).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ðŸ–¼ï¸ Image compression with K-Means\n",
    "\n",
    "> **Enunciado 4 del BoletÃ­n 1.** \"Aplicar K-Means para comprimir la imagen `landscape.ppm` creando paletas de distintos tamaÃ±os. Mostrar los resultados y cuantificar el error de reconstrucciÃ³n para comentar el compromiso entre calidad y compresiÃ³n.\"\n",
    "\n",
    "### Step 4.1 â€” Loading the landscape image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n\nimage = imread(data_paths[\"landscape\"])[:, :, :3]  # drop alpha if present\nprint(image.shape)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The shape `(300, 400, 3)` (height Ã— width Ã— colour channels) tells me I have a\ncolour image. Displaying it in the notebook confirms it is the same landscape we\nused in class.\n\n### Step 4.2 â€” Preparing the pixel matrix"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "h, w, c = image.shape\npixels = image.reshape(-1, c)\n\nscaler_img = StandardScaler()\npixels_scaled = scaler_img.fit_transform(pixels)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Just like in practice0, I reshape so every row is a pixel. I also scale the\nchannels because K-Means behaves better when red/green/blue are on similar\nscales (PPM files use 0â€“255 by default).\n\n### Step 4.3 â€” Trying several palette sizes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "palette_sizes = [4, 8, 16, 32]\ncompressed_versions = {}\n\nfor k in palette_sizes:\n    km = KMeans(n_clusters=k, n_init=10, random_state=0)\n    labels = km.fit_predict(pixels_scaled)\n    palette = scaler_img.inverse_transform(km.cluster_centers_)\n    compressed_pixels = palette[labels]\n    compressed_versions[k] = compressed_pixels.reshape(h, w, c)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "For each `k` I store the reconstructed image so I can compare them later.\n\n### Step 4.4 â€” Measuring reconstruction error"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def mse(original, reconstructed):\n    return np.mean((original - reconstructed) ** 2)\n\nerrors = {k: mse(image, compressed) for k, compressed in compressed_versions.items()}\nerrors"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean-squared error decreases as `k` grows. For example, `k=4` still keeps the\n",
    "general colours but looks blocky, while `k=32` looks almost identical to the\n",
    "original. In the notebook I would show the images side by side.\n",
    "\n",
    "### Step 4.5 â€” Summary\n",
    "\n",
    "- K-Means turns the image into a palette of `k` representative colours.\n",
    "- Standardising the channels prevents the algorithm from favouring green shades.\n",
    "- I can trade fidelity for file size by tuning `k`.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. ðŸ˜€ PCA on synthetic face-like data\n",
    "\n",
    "> **Enunciado 5 del BoletÃ­n 1.** \"Construir el ejemplo de PCA sobre caritas 8Ã—8: calcular las componentes principales a mano y con `sklearn`, proyectar en los dos primeros componentes, reconstruir las imÃ¡genes y analizar la pÃ©rdida de informaciÃ³n.\"\n",
    "\n",
    "This exercise mirrors the hand-crafted 8Ã—8 faces we analysed in class. I reuse a\n",
    "small dataset of smiley faces with different expressions.\n",
    "\n",
    "### Step 5.1 â€” Building the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\n\nfaces = np.array([\n    [\n        0,0,1,1,1,1,0,0,\n        0,1,0,0,0,0,1,0,\n        1,0,1,0,0,1,0,1,\n        1,0,0,0,0,0,0,1,\n        1,0,1,0,0,1,0,1,\n        1,0,0,1,1,0,0,1,\n        0,1,0,0,0,0,1,0,\n        0,0,1,1,1,1,0,0,\n    ],\n    [\n        0,0,1,1,1,1,0,0,\n        0,1,0,0,0,0,1,0,\n        1,0,1,0,0,1,0,1,\n        1,0,0,0,0,0,0,1,\n        1,0,1,0,0,1,0,1,\n        1,0,0,0,0,0,0,1,\n        0,1,0,1,1,0,1,0,\n        0,0,1,0,0,1,0,0,\n    ],\n    [\n        0,0,1,1,1,1,0,0,\n        0,1,0,0,0,0,1,0,\n        1,0,1,0,0,1,0,1,\n        1,0,0,0,0,0,0,1,\n        1,0,1,0,0,1,0,1,\n        1,0,1,1,1,1,0,1,\n        0,1,0,0,0,0,1,0,\n        0,0,1,1,1,1,0,0,\n    ],\n])\n\nn_samples, n_features = faces.shape\nprint(n_samples, n_features)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "I store three facial expressions (neutral, sad, happy) as flattened 8Ã—8 images.\nPrinting `(3, 64)` reassures me that the shape is correct.\n\n### Step 5.2 â€” Centring the data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "faces_mean = faces.mean(axis=0)\nfaces_centered = faces - faces_mean"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "PCA assumes zero-mean data, so I subtract the average face. The mean array looks\nlike a blurry face when reshaped back into 8Ã—8 pixels.\n\n### Step 5.3 â€” Computing PCA manually and with scikit-learn"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from numpy.linalg import svd\nfrom sklearn.decomposition import PCA\n\nu, s, vh = svd(faces_centered, full_matrices=False)\nexplained_var_manual = (s ** 2) / (n_samples - 1)\nexplained_ratio_manual = explained_var_manual / explained_var_manual.sum()\n\npca = PCA()\npca.fit(faces)\n\nexplained_ratio_manual, pca.explained_variance_ratio_"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Both ratios match, which tells me that my manual SVD implementation is correct.\nThe first two components already capture almost all the variance.\n\n### Step 5.4 â€” Projecting and reconstructing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "faces_2d = pca.transform(faces)[:, :2]\nfaces_reconstructed = pca.inverse_transform(\n    np.hstack([faces_2d, np.zeros((n_samples, n_features - 2))])\n)\n\nreconstruction_error = np.mean((faces - faces_reconstructed) ** 2)\nreconstruction_error"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The error is extremely small (< 0.01), meaning two components are enough to\nrepresent these faces. In the notebook I would show the reconstructed images to\nhighlight that the expressions remain recognisable.\n\n### Step 5.5 â€” Final thoughts\n\n- PCA finds a \"happy\" axis and a \"mouth open\" axis without supervision.\n- Keeping only two components still preserves the original shapes, so PCA is a\n  powerful compression technique even for tiny datasets.\n\n---\n\n## âœ… Checklist of what I verified (like in practice0)\n\n- Every dataset path exists before I start using it.\n- After each `read_csv` I call `shape`, `head()`, or `describe()` to sanity\n  check the contents.\n- When choosing hyperparameters (K-Means `k`, DBSCAN `eps`, hierarchical\n  linkage) I compare metrics and explain the decision in plain language.\n- I keep the code blocks short and comment every transformation so that a\n  beginner can follow the reasoning without jumping between files.\n\nThat completes the improved walkthrough! The accompanying notebook mirrors these\nsteps cell by cell so you can rerun everything interactively."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}