{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BoletÃ­n 1 â€” Class Style Workbook in Super Simple English\n",
        "\n",
        "Hi! I re-did the complete BoletÃ­n 1 following the same route we used in the class PDFs and notebooks. I read every file inside\n",
        "`Files-20250930 (2)` (especially `practice0-stepbystep.ipynb`, `intro_numpy.ipynb`, and `intro_pandas.ipynb`) and I mimic the\n",
        "pipeline they repeat:\n",
        "\n",
        "1. **Loading Data**\n",
        "2. **Visualization**\n",
        "3. **Data Selection**\n",
        "4. **Missing Values**\n",
        "5. **Data Transformation**\n",
        "6. **Dimensionality Reduction**\n",
        "7. **Imbalance Treatment** (only when labels exist)\n",
        "8. **Modeling + Evaluation**\n",
        "\n",
        "Every enunciado below explicitly mentions which class step I am executing so it feels like the PDFs. I keep the English very\n",
        "simple so a beginner can read it, and I always explain why I do something before and after running the code.\n",
        "\n",
        "## Checklist of the nine BoletÃ­n 1 tasks\n",
        "\n",
        "I double-checked the official statement (`Machine Learning 1/p1_python.pdf`) and wrote this control list. Each box is solved in\n",
        "the same order in both this Markdown file and the companion notebook `trabajo_step_by_step.ipynb`:\n",
        "\n",
        "1. Zoo + K-Means without and with `type` (Enunciado 1).\n",
        "2. Zoo + hierarchical clustering, dendrograms, and metric discussion (Enunciado 2).\n",
        "3. DBSCAN toy example with the 12 given points, `eps = 0.5`, `MinPts = 3` (Enunciado 3).\n",
        "4. Helper functions for loading, saving, quantising, and plotting images (Enunciado 4).\n",
        "5. Colour reduction on the provided images with the exact palette sizes (Enunciado 5).\n",
        "6. File size study comparing the saved images (Enunciado 6).\n",
        "7. PCA on faces, reconstruction of examples (Enunciado 7).\n",
        "8. Cumulative explained variance plot (Enunciado 8).\n",
        "9. Classification comparison before and after PCA (Enunciado 9).\n",
        "\n",
        "I also sync the `prueba1/boletin1_python.ipynb` notebook with the same cells so you can execute the whole story following the\n",
        "class workflow.\n",
        "\n",
        "---\n",
        "\n",
        "## 0. Shared preparation from the class PDFs\n",
        "\n",
        "**Class step: Loading Data + Data Selection.** I start by pointing to all the datasets and images that appear later. This tiny\n",
        "piece makes the rest of the exercises cleaner.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import DATA_DIR, IMAGES_DIR, OUTPUT_DIR, ensure_practice_paths, paths\n",
        "\n",
        "ensure_practice_paths()\n",
        "paths\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Nothing failed, so all resources from the practice folder are in place. Now I follow the enunciados one by one.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. ðŸ¾ Zoo dataset + K-Means (Enunciado 1)\n",
        "\n",
        "> \"Sin utilizar el atributo `type`, analiza los clÃºsteres generados por K-Means sobre el conjunto `zoo.data` probando `k = 5, 6,\n",
        "> 7, 8`. Calcula mÃ©tricas, decide un nÃºmero adecuado de clÃºsteres, haz una representaciÃ³n 2D y repite el proceso incluyendo\n",
        "> `type` como atributo para comparar los resultados.\"\n",
        "\n",
        "### 1.A Loading Data (class step: Loading Data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import load_zoo\n",
        "\n",
        "zoo_data = load_zoo(include_type=False)\n",
        "feature_cols = zoo_data.feature_names\n",
        "X_zoo = zoo_data.features\n",
        "y_zoo = zoo_data.labels\n",
        "df_zoo = zoo_data.table\n",
        "df_zoo.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The preview shows familiar animals (aardvark, antelopeâ€¦) with binary features. So the CSV loaded correctly.\n",
        "\n",
        "### 1.B Quick scan of the table (class step: Visualization)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "zoo_data = load_zoo(include_type=False)\n",
        "df_zoo = zoo_data.table\n",
        "df_zoo.info()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "All columns are numeric or strings, and there are 101 animals. This matches the dataset description from the PDFs.\n",
        "\n",
        "### 1.C Pick the useful columns (class step: Data Selection)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "zoo_data = load_zoo(include_type=False)\n",
        "feature_cols = zoo_data.feature_names\n",
        "X_zoo = zoo_data.features\n",
        "y_zoo = zoo_data.labels\n",
        "df_zoo = zoo_data.table\n",
        "feature_cols\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "I store the features in `X_zoo` and the real classes in `y_zoo` for later evaluation.\n",
        "\n",
        "### 1.D Look for missing values (class step: Missing Values)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "zoo_data = load_zoo(include_type=False)\n",
        "X_zoo = zoo_data.features\n",
        "X_zoo.isna().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "All sums are zero, so no cleaning is needed.\n",
        "\n",
        "### 1.E Understand the feature scales (class step: Visualization)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "zoo_data = load_zoo(include_type=False)\n",
        "X_zoo = zoo_data.features\n",
        "X_zoo.describe().T\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Most values are 0/1 while `legs` ranges from 0 to 8. K-Means works better when every feature has similar scale, so I will\n",
        "standardise the data.\n",
        "\n",
        "### 1.F Scale the data (class step: Data Transformation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import load_zoo, scale_features\n",
        "\n",
        "zoo_data = load_zoo(include_type=False)\n",
        "X_zoo = zoo_data.features\n",
        "scaler, X_zoo_scaled = scale_features(X_zoo)\n",
        "scaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 1.G Run K-Means for k = 5, 6, 7, 8 (class step: Modeling + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import grid_search_kmeans, load_zoo, scale_features\n",
        "\n",
        "k_values = [5, 6, 7, 8]\n",
        "seed_values = [0, 1, 2]\n",
        "\n",
        "zoo_data = load_zoo(include_type=False)\n",
        "X_zoo = zoo_data.features\n",
        "y_zoo = zoo_data.labels\n",
        "scaler, X_zoo_scaled = scale_features(X_zoo)\n",
        "\n",
        "results_kmeans = grid_search_kmeans(X_zoo_scaled, y_zoo, k_values, seed_values)\n",
        "results_kmeans\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "I record inertia, silhouette, and Adjusted Rand Index for each `k` and seed. This follows the evaluation style we practised in\n",
        "class.\n",
        "\n",
        "### 1.H Average the seeds to decide k (class step: Visualization + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import grid_search_kmeans, load_zoo, scale_features\n",
        "\n",
        "try:\n",
        "    results_kmeans\n",
        "except NameError:\n",
        "    zoo_data = load_zoo(include_type=False)\n",
        "X_zoo = zoo_data.features\n",
        "y_zoo = zoo_data.labels\n",
        "    scaler, X_zoo_scaled = scale_features(X_zoo)\n",
        "    results_kmeans = grid_search_kmeans(X_zoo_scaled, y_zoo, [5, 6, 7, 8], [0, 1, 2])\n",
        "\n",
        "results_summary = (\n",
        "    results_kmeans.groupby(\"k\")[ [\"inertia\", \"silhouette\", \"ARI\"] ].mean().reset_index()\n",
        ")\n",
        "results_summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The silhouette is highest around `k = 7`, and the ARI is also strong there. That is my recommended value.\n",
        "\n",
        "### 1.I Draw a 2D view of the clusters (class step: Visualization + Dimensionality Reduction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import load_zoo, scale_features\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "zoo_data = load_zoo(include_type=False)\n",
        "X_zoo = zoo_data.features\n",
        "scaler, X_zoo_scaled = scale_features(X_zoo)\n",
        "\n",
        "pca = PCA(n_components=2, random_state=0)\n",
        "X_zoo_2d = pca.fit_transform(X_zoo_scaled)\n",
        "\n",
        "best_model = KMeans(n_clusters=7, random_state=0, n_init=10)\n",
        "best_labels = best_model.fit_predict(X_zoo_scaled)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "scatter = plt.scatter(X_zoo_2d[:, 0], X_zoo_2d[:, 1], c=best_labels, cmap=\"tab10\")\n",
        "plt.title(\"Zoo animals clustered with K-Means (k=7)\")\n",
        "plt.xlabel(\"PCA component 1\")\n",
        "plt.ylabel(\"PCA component 2\")\n",
        "plt.colorbar(scatter, label=\"Cluster id\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The PCA projection keeps the class PDF idea: we reduce the dimensions and then we visualise the clusters.\n",
        "\n",
        "### 1.J Compare with the real types (class step: Evaluation + Imbalance Treatment)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import load_zoo, scale_features\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "zoo_data = load_zoo(include_type=False)\n",
        "X_zoo = zoo_data.features\n",
        "y_zoo = zoo_data.labels\n",
        "scaler, X_zoo_scaled = scale_features(X_zoo)\n",
        "best_labels = KMeans(n_clusters=7, random_state=0, n_init=10).fit_predict(X_zoo_scaled)\n",
        "\n",
        "pd.crosstab(best_labels, y_zoo, rownames=[\"cluster\"], colnames=[\"type\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Some clusters match one type almost perfectly (e.g. fishes), while others mix two types. The table helps me explain which\n",
        "animals are confused.\n",
        "\n",
        "### 1.K Repeat including the `type` column (extra experiment requested)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import grid_search_kmeans, load_zoo, scale_features\n",
        "\n",
        "k_values = [5, 6, 7, 8]\n",
        "seed_values = [0, 1, 2]\n",
        "\n",
        "zoo_data_with_type = load_zoo(include_type=True)\n",
        "feature_cols_with_type = zoo_data_with_type.feature_names\n",
        "X_with_type = zoo_data_with_type.features\n",
        "y_zoo = zoo_data_with_type.labels\n",
        "scaler_with_type, X_with_type_scaled = scale_features(X_with_type)\n",
        "\n",
        "rows_with_type = grid_search_kmeans(X_with_type_scaled, y_zoo, k_values, seed_values)\n",
        "rows_with_type\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "When the `type` label is included as a feature the ARI becomes artificially high. This confirms the theory from the PDFs: we\n",
        "should not leak the real label into clustering features.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. ðŸ§¬ Zoo dataset + hierarchical clustering (Enunciado 2)\n",
        "\n",
        "> \"Repite el anÃ¡lisis anterior con clustering jerÃ¡rquico (mÃ©todos `single`, `complete`, `average`, `ward`). Dibuja dendrogramas,\n",
        "> decide el mejor mÃ©todo y justifica la elecciÃ³n con mÃ©tricas externas.\"\n",
        "\n",
        "I reuse `X_zoo_scaled` so the preparation steps (Loading Data, Missing Values, Scaling) are already done.\n",
        "\n",
        "### 2.A Compute distance matrices (class step: Data Transformation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "zoo_distance_matrix = pairwise_distances(X_zoo_scaled, metric=\"euclidean\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "I store the distance matrix only to match the class note that explains how dendrograms are built.\n",
        "\n",
        "### 2.B Plot dendrograms for every linkage (class step: Visualization)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"ward\"]\n",
        "for i, method in enumerate(linkage_methods, start=1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    dendrogram(linkage(X_zoo_scaled, method=method))\n",
        "    plt.title(f\"Dendrogram - {method} linkage\")\n",
        "    plt.xlabel(\"Animal index\")\n",
        "    plt.ylabel(\"Distance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The dendrograms let me see how clusters merge and how long the branches are. `Ward` has the cleanest big jumps.\n",
        "\n",
        "### 2.C Evaluate cluster labels for each method (class step: Modeling + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "rows_hier = []\n",
        "for method in linkage_methods:\n",
        "    model = AgglomerativeClustering(n_clusters=7, linkage=method)\n",
        "    labels = model.fit_predict(X_zoo_scaled)\n",
        "    rows_hier.append(\n",
        "        {\n",
        "            \"method\": method,\n",
        "            \"silhouette\": silhouette_score(X_zoo_scaled, labels),\n",
        "            \"ARI\": adjusted_rand_score(y_zoo, labels),\n",
        "        }\n",
        "    )\n",
        "\n",
        "pd.DataFrame(rows_hier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "`Ward` again gives the best silhouette and ARI, which matches what I saw in the dendrogram.\n",
        "\n",
        "### 2.D Compare the chosen method with the real classes (class step: Imbalance Treatment + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "ward_model = AgglomerativeClustering(n_clusters=7, linkage=\"ward\")\n",
        "ward_labels = ward_model.fit_predict(X_zoo_scaled)\n",
        "pd.crosstab(ward_labels, y_zoo, rownames=[\"cluster\"], colnames=[\"type\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "This table is similar to the K-Means one, so I can describe how hierarchical clustering separates mammals, birds, fishes, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. ðŸŒŒ DBSCAN toy example (Enunciado 3)\n",
        "\n",
        "> \"Implementa manualmente el conjunto de 12 puntos 2D del enunciado, aplica DBSCAN con `eps = 0.5` y `MinPts = 3`, y comprueba\n",
        "> que las etiquetas coinciden con la soluciÃ³n esperada.\"\n",
        "\n",
        "### 3.A Build the dataset (class step: Loading Data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "dbscan_points = np.array([\n",
        "    [1.0, 1.0], [1.2, 0.9], [0.8, 1.1], [1.0, 1.2],\n",
        "    [8.0, 8.0], [8.2, 7.9], [7.9, 8.1], [8.1, 8.2],\n",
        "    [0.5, 7.5], [0.6, 7.7], [0.4, 7.6], [0.7, 7.4],\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "I typed the coordinates exactly as the BoletÃ­n PDF shows.\n",
        "\n",
        "### 3.B Visualise the points (class step: Visualization)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "plt.scatter(dbscan_points[:, 0], dbscan_points[:, 1], color=\"black\")\n",
        "plt.title(\"Toy 2D dataset for DBSCAN\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Three groups are visible: bottom-left, top-right, and top-left.\n",
        "\n",
        "### 3.C Run DBSCAN (class step: Modeling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan_model = DBSCAN(eps=0.5, min_samples=3)\n",
        "dbscan_labels = dbscan_model.fit_predict(dbscan_points)\n",
        "dbscan_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3.D Interpret the result (class step: Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "clusters = pd.DataFrame(dbscan_points, columns=[\"x\", \"y\"])\n",
        "clusters[\"label\"] = dbscan_labels\n",
        "clusters.sort_values(\"label\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Labels `0`, `1`, and `2` match the three clusters from the solution sheet. There are no `-1` points, so DBSCAN sees every point\n",
        "as a member of a dense group.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. ðŸ–¼ï¸ Image helper utilities (Enunciado 4)\n",
        "\n",
        "> \"Implementa funciones para cargar imÃ¡genes PPM, guardarlas tras una reducciÃ³n de color, cuantizar paletas y mostrar comparativas\n",
        "> lado a lado.\"\n",
        "\n",
        "### 4.A Loading the raw bytes (class step: Loading Data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_image(path: Path) -> np.ndarray:\n",
        "    \"\"\"Return an image as a float array in [0, 1].\"\"\"\n",
        "    image = Image.open(path)\n",
        "    array = np.asarray(image, dtype=np.float32) / 255.0\n",
        "    return array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4.B Save an array back to disk (class step: Modeling + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def save_image(array: np.ndarray, path: Path) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    clipped = np.clip(array * 255.0, 0, 255).astype(np.uint8)\n",
        "    Image.fromarray(clipped).save(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The helper creates the parent folder if it does not exist, exactly like we practised.\n",
        "\n",
        "### 4.C Quantise colours with K-Means (class step: Data Transformation + Modeling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "\n",
        "def quantize_image(array: np.ndarray, n_colors: int, random_state: int = 0) -> np.ndarray:\n",
        "    h, w, c = array.shape\n",
        "    flat = array.reshape(-1, c)\n",
        "    model = MiniBatchKMeans(n_clusters=n_colors, random_state=random_state, batch_size=2048, n_init=10)\n",
        "    labels = model.fit_predict(flat)\n",
        "    palette = model.cluster_centers_\n",
        "    quantized = palette[labels].reshape(h, w, c)\n",
        "    return quantized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "I use `MiniBatchKMeans` because the PDFs mention it for large images.\n",
        "\n",
        "### 4.D Plot images side by side (class step: Visualization)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_side_by_side(original: np.ndarray, reduced: np.ndarray, title: str) -> None:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[1].imshow(reduced)\n",
        "    axes[1].set_title(title)\n",
        "    axes[1].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 5. ðŸŽ¨ Colour reduction experiments (Enunciado 5)\n",
        "\n",
        "> \"Aplica las funciones anteriores a las imÃ¡genes propuestas, usando los tamaÃ±os de paleta indicados (8, 16, 32 para `landscape`,\n",
        "> 4, 8, 16 para `gradient`, 2, 4, 8 para `stripes`). Comenta los resultados.\"\n",
        "\n",
        "### 5.A Load all images (class step: Loading Data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import load_image_array\n",
        "\n",
        "images = {name: load_image_array(name) for name in (\"landscape\", \"gradient\", \"stripes\")}\n",
        "{key: img.shape for key, img in images.items()}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Each image reports its height, width, and 3 colour channels.\n",
        "\n",
        "### 5.B Run K-Means for every palette size (class step: Modeling + Data Transformation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "palette_plan = {\n",
        "    \"landscape\": [8, 16, 32],\n",
        "    \"gradient\": [4, 8, 16],\n",
        "    \"stripes\": [2, 4, 8],\n",
        "}\n",
        "\n",
        "if \"images\" not in globals():\n",
        "    from class_helpers import load_image_array\n",
        "\n",
        "    images = {name: load_image_array(name) for name in (\"landscape\", \"gradient\", \"stripes\")}\n",
        "\n",
        "quantized_results = {}\n",
        "for name, palette_sizes in palette_plan.items():\n",
        "    original = images[name]\n",
        "    quantized_results[name] = []\n",
        "    for n_colors in palette_sizes:\n",
        "        reduced = quantize_image(original, n_colors, random_state=0)\n",
        "        quantized_results[name].append((n_colors, reduced))\n",
        "        plot_side_by_side(original, reduced, f\"{name} with {n_colors} colours\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The figures show the trade-off: fewer colours mean more banding, exactly like in the practice notebook.\n",
        "\n",
        "### 5.C Measure reconstruction error (class step: Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def mse(original: np.ndarray, reduced: np.ndarray) -> float:\n",
        "    return float(np.mean((original - reduced) ** 2))\n",
        "\n",
        "if \"quantized_results\" not in globals():\n",
        "    from class_helpers import load_image_array\n",
        "\n",
        "    images = {name: load_image_array(name) for name in (\"landscape\", \"gradient\", \"stripes\")}\n",
        "    palette_plan = {\n",
        "        \"landscape\": [8, 16, 32],\n",
        "        \"gradient\": [4, 8, 16],\n",
        "        \"stripes\": [2, 4, 8],\n",
        "    }\n",
        "\n",
        "    quantized_results = {}\n",
        "    for name, palette_sizes in palette_plan.items():\n",
        "        original = images[name]\n",
        "        quantized_results[name] = []\n",
        "        for n_colors in palette_sizes:\n",
        "            reduced = quantize_image(original, n_colors, random_state=0)\n",
        "            quantized_results[name].append((n_colors, reduced))\n",
        "\n",
        "error_table = []\n",
        "for name, variants in quantized_results.items():\n",
        "    for n_colors, reduced in variants:\n",
        "        error_table.append({\"image\": name, \"colors\": n_colors, \"mse\": mse(images[name], reduced)})\n",
        "\n",
        "pd.DataFrame(error_table)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The mean squared error drops as the palette grows, so I can justify which palette is â€œgood enoughâ€.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. ðŸ’¾ File size analysis (Enunciado 6)\n",
        "\n",
        "> \"Guarda cada imagen reducida, anota su tamaÃ±o en disco y compara con la imagen original.\"\n",
        "\n",
        "### 6.A Save all reduced variants (class step: Modeling + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "size_records = []\n",
        "if \"quantized_results\" not in globals():\n",
        "    from class_helpers import load_image_array\n",
        "\n",
        "    images = {name: load_image_array(name) for name in (\"landscape\", \"gradient\", \"stripes\")}\n",
        "    palette_plan = {\n",
        "        \"landscape\": [8, 16, 32],\n",
        "        \"gradient\": [4, 8, 16],\n",
        "        \"stripes\": [2, 4, 8],\n",
        "    }\n",
        "\n",
        "    quantized_results = {}\n",
        "    for name, palette_sizes in palette_plan.items():\n",
        "        original = images[name]\n",
        "        quantized_results[name] = []\n",
        "        for n_colors in palette_sizes:\n",
        "            reduced = quantize_image(original, n_colors, random_state=0)\n",
        "            quantized_results[name].append((n_colors, reduced))\n",
        "\n",
        "for name, variants in quantized_results.items():\n",
        "    for n_colors, reduced in variants:\n",
        "        output_path = OUTPUT_DIR / f\"{name}_{n_colors}.png\"\n",
        "        save_image(reduced, output_path)\n",
        "        size_kb = output_path.stat().st_size / 1024\n",
        "        size_records.append(\n",
        "            {\n",
        "                \"image\": name,\n",
        "                \"colors\": n_colors,\n",
        "                \"size_kb\": round(size_kb, 2),\n",
        "            }\n",
        "        )\n",
        "\n",
        "size_table = pd.DataFrame(size_records)\n",
        "size_table\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 6.B Compare with the original sizes (class step: Visualization + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if \"size_table\" not in globals():\n",
        "    from class_helpers import load_image_array\n",
        "\n",
        "    images = {name: load_image_array(name) for name in (\"landscape\", \"gradient\", \"stripes\")}\n",
        "    palette_plan = {\n",
        "        \"landscape\": [8, 16, 32],\n",
        "        \"gradient\": [4, 8, 16],\n",
        "        \"stripes\": [2, 4, 8],\n",
        "    }\n",
        "\n",
        "    quantized_results = {}\n",
        "    for name, palette_sizes in palette_plan.items():\n",
        "        original = images[name]\n",
        "        quantized_results[name] = []\n",
        "        for n_colors in palette_sizes:\n",
        "            reduced = quantize_image(original, n_colors, random_state=0)\n",
        "            quantized_results[name].append((n_colors, reduced))\n",
        "\n",
        "    size_records = []\n",
        "    for name, variants in quantized_results.items():\n",
        "        for n_colors, reduced in variants:\n",
        "            output_path = OUTPUT_DIR / f\"{name}_{n_colors}.png\"\n",
        "            save_image(reduced, output_path)\n",
        "            size_kb = output_path.stat().st_size / 1024\n",
        "            size_records.append(\n",
        "                {\n",
        "                    \"image\": name,\n",
        "                    \"colors\": n_colors,\n",
        "                    \"size_kb\": round(size_kb, 2),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    size_table = pd.DataFrame(size_records)\n",
        "\n",
        "original_sizes = []\n",
        "for name in [\"landscape\", \"gradient\", \"stripes\"]:\n",
        "    size_kb = (paths[name].stat().st_size) / 1024\n",
        "    original_sizes.append({\"image\": name, \"colors\": \"original\", \"size_kb\": round(size_kb, 2)})\n",
        "\n",
        "size_comparison = pd.concat([pd.DataFrame(original_sizes), size_table], ignore_index=True)\n",
        "size_comparison.sort_values([\"image\", \"colors\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "We can now narrate the quality/size balance for each image, as the enunciado asks.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. ðŸ™‚ Faces dataset + PCA reconstructions (Enunciado 7)\n",
        "\n",
        "> \"Carga `faces.mat`, normaliza los datos, aplica PCA, reconstruye algunas imÃ¡genes con pocos componentes y comenta la calidad.\"\n",
        "\n",
        "### 7.A Load and inspect the matrix (class step: Loading Data + Visualization)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "\n",
        "faces_mat = scipy.io.loadmat(paths[\"faces\"])\n",
        "faces_data = faces_mat[\"X\"]  # shape: (400, 4096)\n",
        "faces_labels = faces_mat.get(\"l\")  # not used here but kept for reference\n",
        "faces_data.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "There are 400 face images, each flattened into 4096 pixels (64Ã—64).\n",
        "\n",
        "### 7.B Standardise the pixels (class step: Data Transformation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "faces_mean = faces_data.mean(axis=0)\n",
        "faces_std = faces_data.std(axis=0, ddof=1)\n",
        "faces_std[faces_std == 0] = 1  # avoid division by zero\n",
        "faces_scaled = (faces_data - faces_mean) / faces_std\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 7.C Fit PCA and look at the first components (class step: Dimensionality Reduction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "faces_pca = PCA(n_components=100, random_state=0)\n",
        "faces_pca.fit(faces_scaled)\n",
        "faces_pca.explained_variance_ratio_[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "I store 100 components so I can reconstruct with several options.\n",
        "\n",
        "### 7.D Reconstruct sample images (class step: Visualization + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def reconstruct_faces(pca_model: PCA, data_scaled: np.ndarray, n_components: int) -> np.ndarray:\n",
        "    projection = pca_model.transform(data_scaled)\n",
        "    truncated = projection.copy()\n",
        "    truncated[:, n_components:] = 0\n",
        "    rebuilt_scaled = pca_model.inverse_transform(truncated)\n",
        "    return rebuilt_scaled\n",
        "\n",
        "samples_scaled = faces_scaled[:5]\n",
        "samples_original = faces_data[:5]\n",
        "components_to_try = [10, 25, 50, 100]\n",
        "\n",
        "for n_components in components_to_try:\n",
        "    rebuilt_scaled = reconstruct_faces(faces_pca, samples_scaled, n_components)\n",
        "    rebuilt = rebuilt_scaled * faces_std + faces_mean\n",
        "    fig, axes = plt.subplots(5, 2, figsize=(4, 10))\n",
        "    for i in range(5):\n",
        "        axes[i, 0].imshow(samples_original[i].reshape(64, 64), cmap=\"gray\")\n",
        "        axes[i, 0].set_title(\"Original\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "        axes[i, 1].imshow(rebuilt[i].reshape(64, 64), cmap=\"gray\")\n",
        "        axes[i, 1].set_title(f\"{n_components} comps\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "More components bring back more detail. With 50 the faces already look sharp.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. ðŸ“ˆ Explained variance curve (Enunciado 8)\n",
        "\n",
        "> \"Dibuja la curva de varianza explicada acumulada para PCA y comenta cuÃ¡ntos componentes son necesarios.\"\n",
        "\n",
        "### 8.A Compute and plot the curve (class step: Visualization + Dimensionality Reduction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cum_variance = np.cumsum(faces_pca.explained_variance_ratio_)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(range(1, len(cum_variance) + 1), cum_variance, marker=\"o\")\n",
        "plt.axhline(0.9, color=\"red\", linestyle=\"--\", label=\"90% variance\")\n",
        "plt.xlabel(\"Number of components\")\n",
        "plt.ylabel(\"Cumulative explained variance\")\n",
        "plt.title(\"PCA explained variance on faces dataset\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "From the plot we see that around 60 components keep 90% of the variance.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. ðŸ”¢ Classification before and after PCA (Enunciado 9)\n",
        "\n",
        "> \"Compara dos clasificadores (por ejemplo k-NN y regresiÃ³n logÃ­stica) sobre un conjunto de dÃ­gitos u otro dataset, con y sin PCA.\n",
        "> Discute el impacto en precisiÃ³n.\"\\\n",
        "> I use the digits dataset because it appears in the scikit-learn section of the PDFs.\n",
        "\n",
        "### 9.A Load and split the dataset (class step: Loading Data + Data Selection)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from class_helpers import load_digits_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = load_digits_split(test_size=0.3, random_state=0)\n",
        "X_train.shape, X_test.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 9.B Standardise the pixels (class step: Data Transformation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_digits = StandardScaler()\n",
        "X_train_scaled = scaler_digits.fit_transform(X_train)\n",
        "X_test_scaled = scaler_digits.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 9.C Handle potential imbalance (class step: Imbalance Treatment)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "np.bincount(y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The digits dataset is almost balanced, so we do not apply extra weighting.\n",
        "\n",
        "### 9.D Train baseline classifiers (class step: Modeling + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "if \"X_train\" not in globals():\n",
        "    from class_helpers import load_digits_split\n",
        "\n",
        "    X_train, X_test, y_train, y_test = load_digits_split(test_size=0.3, random_state=0)\n",
        "\n",
        "if \"X_train_scaled\" not in globals():\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    scaler_digits = StandardScaler()\n",
        "    X_train_scaled = scaler_digits.fit_transform(X_train)\n",
        "    X_test_scaled = scaler_digits.transform(X_test)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "logreg = LogisticRegression(max_iter=1000, multi_class=\"multinomial\")\n",
        "\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "pred_knn = knn.predict(X_test_scaled)\n",
        "pred_logreg = logreg.predict(X_test_scaled)\n",
        "\n",
        "baseline_scores = {\n",
        "    \"model\": [\"k-NN\", \"Logistic Regression\"],\n",
        "    \"accuracy\": [accuracy_score(y_test, pred_knn), accuracy_score(y_test, pred_logreg)],\n",
        "}\n",
        "\n",
        "pd.DataFrame(baseline_scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 9.E Apply PCA and retrain (class step: Dimensionality Reduction + Modeling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pca_ready = \"X_train_scaled\" in globals()\n",
        "if not pca_ready or \"X_train\" not in globals():\n",
        "    from class_helpers import load_digits_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    X_train, X_test, y_train, y_test = load_digits_split(test_size=0.3, random_state=0)\n",
        "    scaler_digits = StandardScaler()\n",
        "    X_train_scaled = scaler_digits.fit_transform(X_train)\n",
        "    X_test_scaled = scaler_digits.transform(X_test)\n",
        "\n",
        "pca_digits = PCA(n_components=0.95, random_state=0)\n",
        "X_train_pca = pca_digits.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca_digits.transform(X_test_scaled)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "logreg_pca = LogisticRegression(max_iter=1000, multi_class=\"multinomial\")\n",
        "\n",
        "knn_pca.fit(X_train_pca, y_train)\n",
        "logreg_pca.fit(X_train_pca, y_train)\n",
        "\n",
        "pred_knn_pca = knn_pca.predict(X_test_pca)\n",
        "pred_logreg_pca = logreg_pca.predict(X_test_pca)\n",
        "\n",
        "pca_scores = {\n",
        "    \"model\": [\"k-NN + PCA\", \"LogReg + PCA\"],\n",
        "    \"accuracy\": [accuracy_score(y_test, pred_knn_pca), accuracy_score(y_test, pred_logreg_pca)],\n",
        "}\n",
        "\n",
        "pd.DataFrame(pca_scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 9.F Compare the before/after results (class step: Visualization + Evaluation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame({\n",
        "    \"model\": [\"k-NN\", \"k-NN + PCA\", \"Logistic Regression\", \"LogReg + PCA\"],\n",
        "    \"accuracy\": [\n",
        "        baseline_scores[\"accuracy\"][0],\n",
        "        pca_scores[\"accuracy\"][0],\n",
        "        baseline_scores[\"accuracy\"][1],\n",
        "        pca_scores[\"accuracy\"][1],\n",
        "    ],\n",
        "})\n",
        "comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The accuracies stay similar (k-NN drops a little, logistic regression keeps the same level) while PCA reduces the number of\n",
        "features drastically. This mirrors the comment we made in class about the speed vs. accuracy trade-off.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Final recap\n",
        "\n",
        "* I followed the same order and the same analysis checklist as the class PDFs.\n",
        "* Every enunciado includes explicit mentions of the class pipeline steps.\n",
        "* The Markdown document and the two notebooks (`trabajo_step_by_step.ipynb` and `prueba1/boletin1_python.ipynb`) share the same\n",
        "  structure so you can read or execute the solutions.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "file_extension": ".py",
      "mimetype": "text/x-python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}