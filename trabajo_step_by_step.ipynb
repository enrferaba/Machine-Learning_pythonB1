  "cells": [
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Boletin 1 step by step notebook\n",
        "\n",
        "This notebook follows the class work with the new image pack. I go module by module.\n",
        "Every block is short, written in basic English, and easy to test. Run each cell in order.\n"
      ]
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Prepare folders and tools\n",
        "\n",
        "Goal: confirm that the helper files and images from the teacher package are ready.\n",
        "If something is missing the helper will tell us how to fix it.\n"
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from class_helpers import (\n",
        "    DATA_DIR,\n",
        "    FILES_DIR,\n",
        "    IMAGES_DIR,\n",
        "    OUTPUT_DIR,\n",
        "    ensure_practice_paths,\n",
        "    load_zoo,\n",
        "    scale_features,\n",
        "    load_image_array,\n",
        "    load_faces,\n",
        "    load_digits_split,\n",
        ")\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n"
      ]
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "ensure_practice_paths()\n",
        "print(\"Data directory:\", DATA_DIR)\n",
        "print(\"Files directory:\", FILES_DIR)\n",
        "print(\"Images directory:\", IMAGES_DIR)\n",
        "print(\"Output directory:\", OUTPUT_DIR)\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The helper created every folder. Now I check which images are present before any processing.\n"
      ]
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "image_paths = sorted(IMAGES_DIR.glob(\"*.ppm\"))\n",
        "for path in image_paths:\n",
        "    size_kb = path.stat().st_size / 1024\n",
        "    print(f\"{path.name}: {size_kb:.1f} KB\")\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Everything looks good, so I can begin with Module 1 about the Zoo dataset.\n"
      ]
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Zoo dataset warm up\n",
        "\n",
        "Goal: load the table, explore the columns, and prepare the data like in class.\n",
        "I keep the steps small so a new student can follow the logic.\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Load the CSV file\n"
      ]
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "zoo_data = load_zoo(include_type=False)\n",
        "zoo_table = zoo_data.table.copy()\n",
        "print(\"Rows:\", len(zoo_table))\n",
        "print(\"Columns:\", list(zoo_table.columns))\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I also want to see the first animals to make sure the file is correct.\n"
      ]
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "zoo_table.head()\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Split features and labels\n"
      ]
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "feature_names = zoo_data.feature_names\n",
        "X_zoo = zoo_data.features.copy()\n",
        "y_zoo = zoo_data.labels.copy()\n",
        "print(\"Feature count:\", len(feature_names))\n",
        "print(\"Target name: type\")\n",
        "X_zoo.head()\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Quick data checks\n",
        "I look for missing values and I note the scale of each column.\n"
      ]
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "missing_values = X_zoo.isna().sum()\n",
        "print(missing_values)\n"
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_zoo.describe().T\n"
      ]
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The feature \"legs\" has a wider range. I scale every column to zero mean and unit variance.\n"
    },
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "scaler_zoo, X_zoo_scaled = scale_features(X_zoo)\n",
        "print(\"Scaled shape:\", X_zoo_scaled.shape)\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. K-Means on the Zoo animals\n",
        "\n",
        "Goal: repeat the class experiment with k from 5 to 8. I store the inertia,\n",
        "the silhouette score, and the Adjusted Rand Index. The loop is verbose on purpose.\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Run the clustering loop\n"
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "\n",
        "k_trials = []\n",
        "for k in [5, 6, 7, 8]:\n",
        "    for seed in [0, 1, 2]:\n",
        "        model = KMeans(n_clusters=k, random_state=seed, n_init=10)\n",
        "        labels = model.fit_predict(X_zoo_scaled)\n",
        "        inertia = model.inertia_\n",
        "        silhouette = silhouette_score(X_zoo_scaled, labels)\n",
        "        ari = adjusted_rand_score(y_zoo, labels)\n",
        "        k_trials.append({\n",
        "            \"k\": k,\n",
        "            \"seed\": seed,\n",
        "            \"inertia\": inertia,\n",
        "            \"silhouette\": silhouette,\n",
        "            \"ARI\": ari,\n",
        "        })\n",
        "        print(f\"k={k}, seed={seed} \u2192 inertia={inertia:.1f}, silhouette={silhouette:.3f}, ARI={ari:.3f}\")\n",
        "results_kmeans = pd.DataFrame(k_trials)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Compare the results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "results_summary = results_kmeans.groupby(\"k\")[\"silhouette\", \"ARI\"].mean()\n",
        "results_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The best average scores happen near k = 7. Next I visualise the clusters with PCA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Plot a two dimensional view\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA(n_components=2, random_state=0)\n",
        "zoo_2d = pca.fit_transform(X_zoo_scaled)\n",
        "best_model = KMeans(n_clusters=7, random_state=0, n_init=10)\n",
        "best_labels = best_model.fit_predict(X_zoo_scaled)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "scatter = plt.scatter(zoo_2d[:, 0], zoo_2d[:, 1], c=best_labels, cmap=\"tab10\")\n",
        "plt.title(\"Zoo animals grouped with K-Means (k=7)\")\n",
        "plt.xlabel(\"PCA component 1\")\n",
        "plt.ylabel(\"PCA component 2\")\n",
        "plt.colorbar(scatter, label=\"cluster\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Compare clusters with real types\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "comparison_table = pd.crosstab(y_zoo, best_labels, rownames=[\"type\"], colnames=[\"cluster\"])\n",
        "comparison_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hierarchical clustering on the Zoo animals\n",
        "\n",
        "Goal: build dendrograms and compare linkage strategies before choosing Ward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Create the dendrograms\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "zoo_distances = pairwise_distances(X_zoo_scaled)\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"ward\"]\n",
        "plt.figure(figsize=(14, 10))\n",
        "for index, method in enumerate(linkage_methods, start=1):\n",
        "    plt.subplot(2, 2, index)\n",
        "    linkage_matrix = linkage(zoo_distances, method=method)\n",
        "    dendrogram(linkage_matrix, no_labels=True)\n",
        "    plt.title(f\"Linkage: {method}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Pick the best linkage with metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "\n",
        "linkage_scores = []\n",
        "for method in linkage_methods:\n",
        "    model = AgglomerativeClustering(n_clusters=7, linkage=method)\n",
        "    labels = model.fit_predict(X_zoo_scaled)\n",
        "    sil = silhouette_score(X_zoo_scaled, labels)\n",
        "    ari = adjusted_rand_score(y_zoo, labels)\n",
        "    linkage_scores.append({\"linkage\": method, \"silhouette\": sil, \"ARI\": ari})\n",
        "    print(f\"linkage={method} \u2192 silhouette={sil:.3f}, ARI={ari:.3f}\")\n",
        "linkage_results = pd.DataFrame(linkage_scores)\n",
        "linkage_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ward keeps the best balance, so I show its cluster mix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "ward_model = AgglomerativeClustering(n_clusters=7, linkage=\"ward\")\n",
        "ward_labels = ward_model.fit_predict(X_zoo_scaled)\n",
        "ward_table = pd.crosstab(y_zoo, ward_labels, rownames=[\"type\"], colnames=[\"cluster\"])\n",
        "ward_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DBSCAN toy example\n",
        "\n",
        "Goal: copy the coordinates from the Boletin and run DBSCAN step by step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Create the toy points\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "toy_points = np.array([\n",
        "    [1.0, 1.0], [1.2, 0.9], [0.8, 1.1], [1.0, 1.2],\n",
        "    [8.0, 8.0], [8.2, 8.1], [7.9, 8.2], [8.1, 7.8],\n",
        "    [4.5, 9.0], [4.7, 9.2], [4.3, 8.8], [4.6, 9.1],\n",
        "])\n",
        "toy_df = pd.DataFrame(toy_points, columns=[\"x\", \"y\"])\n",
        "toy_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Plot the raw points\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "plt.scatter(toy_df[\"x\"], toy_df[\"y\"], color=\"black\")\n",
        "plt.title(\"Toy dataset before DBSCAN\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Apply DBSCAN and sort the labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan_model = DBSCAN(eps=0.5, min_samples=3)\n",
        "toy_labels = dbscan_model.fit_predict(toy_points)\n",
        "toy_df[\"cluster\"] = toy_labels\n",
        "toy_df.sort_values(\"cluster\").reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Image colour reduction\n",
        "\n",
        "Goal: load each image, reduce its colours with MiniBatchKMeans, and compare outputs.\n",
        "I save the reduced files inside the new reduced_images folder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Load the images as arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "images = {\n",
        "    name: load_image_array(name)\n",
        "    for name in (\"landscape\", \"gradient\", \"stripes\")\n",
        "}\n",
        "for name, array in images.items():\n",
        "    print(f\"{name}: shape={array.shape}, min={array.min():.3f}, max={array.max():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Helper functions for saving and plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def save_image(array: np.ndarray, path: Path) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    clipped = np.clip(array * 255.0, 0, 255).astype(np.uint8)\n",
        "    Image.fromarray(clipped).save(path)\n",
        "    print(\"Saved\", path)\n",
        "\n",
        "def quantize_image(array: np.ndarray, n_colors: int, random_state: int = 0) -> np.ndarray:\n",
        "    from sklearn.cluster import MiniBatchKMeans\n",
        "    pixels = array.reshape(-1, 3)\n",
        "    model = MiniBatchKMeans(n_clusters=n_colors, random_state=random_state)\n",
        "    labels = model.fit_predict(pixels)\n",
        "    palette = model.cluster_centers_\n",
        "    reduced_pixels = palette[labels]\n",
        "    return reduced_pixels.reshape(array.shape)\n",
        "\n",
        "def plot_side_by_side(original: np.ndarray, reduced: np.ndarray, title: str) -> None:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[1].imshow(reduced)\n",
        "    axes[1].set_title(\"Reduced\")\n",
        "    axes[1].axis(\"off\")\n",
        "    fig.suptitle(title)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Run experiments for each palette size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "palette_plan = {\n",
        "    \"landscape\": [8, 16, 32],\n",
        "    \"gradient\": [4, 8, 16],\n",
        "    \"stripes\": [2, 4, 8],\n",
        "}\n",
        "quantized_results = {}\n",
        "for name, palette_sizes in palette_plan.items():\n",
        "    original = images[name]\n",
        "    quantized_results[name] = {}\n",
        "    for n_colors in palette_sizes:\n",
        "        reduced = quantize_image(original, n_colors=n_colors, random_state=0)\n",
        "        quantized_results[name][n_colors] = reduced\n",
        "        save_image(reduced, OUTPUT_DIR / f\"{name}_k{n_colors}.png\")\n",
        "        plot_side_by_side(original, reduced, f\"{name} with {n_colors} colours\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Measure reconstruction error\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def mse(original: np.ndarray, reduced: np.ndarray) -> float:\n",
        "    return float(np.mean((original - reduced) ** 2))\n",
        "\n",
        "error_rows = []\n",
        "for name, reduced_dict in quantized_results.items():\n",
        "    original = images[name]\n",
        "    for n_colors, reduced in reduced_dict.items():\n",
        "        error_rows.append({\n",
        "            \"image\": name,\n",
        "            \"palette\": n_colors,\n",
        "            \"mse\": mse(original, reduced),\n",
        "        })\n",
        "error_table = pd.DataFrame(error_rows)\n",
        "error_table.sort_values([\"image\", \"palette\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. File size comparison\n",
        "\n",
        "Goal: compare the reduced PNG sizes with the original PPM files.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "size_records = []\n",
        "for path in image_paths:\n",
        "    size_records.append({\n",
        "        \"name\": path.stem,\n",
        "        \"variant\": \"original\",\n",
        "        \"size_kb\": path.stat().st_size / 1024,\n",
        "    })\n",
        "for name, reduced_dict in quantized_results.items():\n",
        "    for n_colors in reduced_dict:\n",
        "        output_path = OUTPUT_DIR / f\"{name}_k{n_colors}.png\"\n",
        "        size_records.append({\n",
        "            \"name\": name,\n",
        "            \"variant\": f\"k={n_colors}\",\n",
        "            \"size_kb\": output_path.stat().st_size / 1024,\n",
        "        })\n",
        "size_table = pd.DataFrame(size_records)\n",
        "size_table.sort_values([\"name\", \"variant\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Faces dataset with PCA\n",
        "\n",
        "Goal: standardise the pixel data, fit PCA, and rebuild faces with different counts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Load and scale the faces\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "faces_data, faces_labels = load_faces()\n",
        "print(\"Faces shape:\", faces_data.shape)\n",
        "faces_mean = faces_data.mean(axis=0)\n",
        "faces_std = faces_data.std(axis=0, ddof=1)\n",
        "faces_std[faces_std == 0] = 1\n",
        "faces_scaled = (faces_data - faces_mean) / faces_std\n",
        "print(\"Scaled faces shape:\", faces_scaled.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Fit PCA and inspect variance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "faces_pca = PCA(n_components=100, random_state=0)\n",
        "faces_pca.fit(faces_scaled)\n",
        "variance_info = pd.DataFrame({\n",
        "    \"component\": np.arange(1, 11),\n",
        "    \"explained_variance\": faces_pca.explained_variance_ratio_[:10],\n",
        "})\n",
        "variance_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 Reconstruct sample faces\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def reconstruct_faces(pca_model: PCA, data_scaled: np.ndarray, n_components: int) -> np.ndarray:\n",
        "    projection = pca_model.transform(data_scaled)\n",
        "    limited = projection[:, :n_components]\n",
        "    zeros = np.zeros_like(projection)\n",
        "    zeros[:, :n_components] = limited\n",
        "    rebuilt = pca_model.inverse_transform(zeros)\n",
        "    return rebuilt * faces_std + faces_mean\n",
        "\n",
        "components_to_try = [10, 25, 50, 75]\n",
        "sample_index = 0\n",
        "original_face = faces_data[sample_index].reshape(64, 64)\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.subplot(1, len(components_to_try) + 1, 1)\n",
        "plt.imshow(original_face, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Original\")\n",
        "for plot_index, n_components in enumerate(components_to_try, start=2):\n",
        "    rebuilt = reconstruct_faces(faces_pca, faces_scaled[[sample_index]], n_components)[0]\n",
        "    plt.subplot(1, len(components_to_try) + 1, plot_index)\n",
        "    plt.imshow(rebuilt.reshape(64, 64), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"{n_components} comps\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.4 Plot the cumulative variance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cumulative_variance = np.cumsum(faces_pca.explained_variance_ratio_)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance)\n",
        "plt.axhline(0.9, color=\"red\", linestyle=\"--\", label=\"90% threshold\")\n",
        "plt.xlabel(\"Number of components\")\n",
        "plt.ylabel(\"Cumulative variance\")\n",
        "plt.title(\"Faces PCA cumulative variance\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Digits classification before and after PCA\n",
        "\n",
        "Goal: repeat the digits workflow with StandardScaler, two models, and a PCA version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Load and scale the digits dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = load_digits_split(test_size=0.3, random_state=0)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_digits = StandardScaler()\n",
        "X_train_scaled = scaler_digits.fit_transform(X_train)\n",
        "X_test_scaled = scaler_digits.transform(X_test)\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 Check class balance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_counts = pd.Series(y_train).value_counts().sort_index()\n",
        "train_counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3 Train baseline classifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "knn_pred = knn.predict(X_test_scaled)\n",
        "knn_score = accuracy_score(y_test, knn_pred)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"auto\")\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "logreg_pred = logreg.predict(X_test_scaled)\n",
        "logreg_score = accuracy_score(y_test, logreg_pred)\n",
        "print(f\"k-NN accuracy: {knn_score:.3f}\")\n",
        "print(f\"Logistic Regression accuracy: {logreg_score:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4 Apply PCA and retrain\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "digits_pca = PCA(n_components=40, random_state=0)\n",
        "digits_pca.fit(X_train_scaled)\n",
        "X_train_pca = digits_pca.transform(X_train_scaled)\n",
        "X_test_pca = digits_pca.transform(X_test_scaled)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_train_pca, y_train)\n",
        "knn_pca_pred = knn_pca.predict(X_test_pca)\n",
        "knn_pca_score = accuracy_score(y_test, knn_pca_pred)\n",
        "\n",
        "logreg_pca = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"auto\")\n",
        "logreg_pca.fit(X_train_pca, y_train)\n",
        "logreg_pca_pred = logreg_pca.predict(X_test_pca)\n",
        "logreg_pca_score = accuracy_score(y_test, logreg_pca_pred)\n",
        "print(f\"k-NN + PCA accuracy: {knn_pca_score:.3f}\")\n",
        "print(f\"LogReg + PCA accuracy: {logreg_pca_score:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.5 Compare all scores and component counts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame([\n",
        "    {\"model\": \"k-NN\", \"accuracy\": knn_score, \"features\": X_train_scaled.shape[1]},\n",
        "    {\"model\": \"k-NN + PCA\", \"accuracy\": knn_pca_score, \"features\": X_train_pca.shape[1]},\n",
        "    {\"model\": \"Logistic Regression\", \"accuracy\": logreg_score, \"features\": X_train_scaled.shape[1]},\n",
        "    {\"model\": \"LogReg + PCA\", \"accuracy\": logreg_pca_score, \"features\": X_train_pca.shape[1]},\n",
        "])\n",
        "comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Wrap up\n",
        "\n",
        "I finished every module with the same structure used in class. Each section stays simple,\n",
        "prints intermediate values, and saves the new image results inside the files/reduced_images folder.\n",
        "Re-run any cell to review the ideas at your own pace.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5